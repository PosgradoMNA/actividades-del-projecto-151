{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwhEVOGns+lYN4hfUR6tIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-del-projecto-151/blob/main/Actividad_Semanal_Preguntas_4_11102022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkMu6fGLkKVu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Cuál es el número de componentes mínimo y por qué?\n",
        "El número de componentes mínimos es 10, la razón es que es los que suman el monto más alto % varianza explicada de forma acumulada:**\n",
        "\n",
        "% varianza explicada\t% varianza acumulada\n",
        "PC1\t38.50\t38.497171\n",
        "PC2\t19.56\t58.055242\n",
        "PC3\t9.89\t67.944875\n",
        "PC4\t7.28\t75.229366\n",
        "PC5\t4.76\t79.984491\n",
        "PC6\t4.22\t84.205772\n",
        "PC7\t3.47\t87.679428\n",
        "PC8\t3.12\t90.796939\n",
        "PC9\t2.55\t93.342473\n",
        "PC10\t2.18\t95.524555 <---Aquí se llega al 95%\n",
        "PC11\t1.71\t97.239146\n",
        "PC12\t1.03\t98.270717\n",
        "PC13\t0.93\t99.205278\n",
        "PC14\t0.44\t99.644698\n",
        "PC15\t0.30\t99.947702\n",
        "PC16\t0.04\t99.983243\n",
        "PC17\t0.01\t99.991498\n",
        "PC18\t0.00\t99.995599\n",
        "PC19\t0.00\t99.998299\n",
        "PC20\t0.00\t100.000000\n",
        "PC21\t0.00\t100.000000\n",
        "\n",
        "En la tabla anterior aplicamos el PCA dentro de la matriz de datos y  ese % varianza explicada, llega a 95% en el componente número 10 (PC10), el resto de los componentes, aunque siguen sumando para llegar por ejemplo a 99.99 en el componente 19; al verificar la suma de varianzas acumulada dentro de la matriz de datos original, se llega a ese nivel de % varianza explicada, con relación a la varianza total, hasta la variable X23:\n",
        "\n",
        "Porcentaje Varianza\tPorcentaje Varianza Acumulada\n",
        "X1\t4.166667\t4.166667\n",
        "X2\t4.166667\t8.333333\n",
        "X3\t4.166667\t12.500000\n",
        "X4\t4.166667\t16.666667\n",
        "X5\t4.166667\t20.833333\n",
        "X6\t4.166667\t25.000000\n",
        "X7\t4.166667\t29.166667\n",
        "X8\t4.166667\t33.333333\n",
        "X9\t4.166667\t37.500000\n",
        "X10\t4.166667\t41.666667\n",
        "X11\t4.166667\t45.833333\n",
        "X12\t4.166667\t50.000000\n",
        "X13\t4.166667\t54.166667\n",
        "X14\t4.166667\t58.333333\n",
        "X15\t4.166667\t62.500000\n",
        "X16\t4.166667\t66.666667\n",
        "X17\t4.166667\t70.833333\n",
        "X18\t4.166667\t75.000000\n",
        "X19\t4.166667\t79.166667\n",
        "X20\t4.166667\t83.333333\n",
        "X21\t4.166667\t87.500000\n",
        "X22\t4.166667\t91.666667\n",
        "X23\t4.166667\t95.833333  <--- Aquí se llega al 95% \n",
        "Y\t4.166667\t100.000000\n",
        "\n",
        "**¿Cuál es la variación de los datos que representan esos componentes?**\n",
        "\n",
        "La variación es del 95.524555%, que al relacionarlos contra la información de los datos originales, la diferencia solo es 0.3087%, contra el 95.833333%\n",
        "\n",
        "**¿Cuál es la pérdida de información después de realizar PCA?**\n",
        "\n",
        "**De las variables originales, ¿Cuál tiene mayor y cuál tiene menor importancia en los componentes principales?**\n",
        "\n",
        "**¿Cuándo se recomienda realizar un PCA y qué beneficios ofrece para Machine Learning?**\n",
        "\n",
        "Cuando los datos analizados son muy grandes y existen correlaciones importantes entre los datos. PCA ayuda para \"reducir\", la muestra de datos, pero mantiene la varianza entre datos que al final de cuentas, al mantener el mismo nivel de variabilidad es lo importante para las predicciones. Por lo tanto, aplicar PCA depende del entendimiento de datos al analizar la correlación entre ellos, es decir, al aplicar la revisión de correlación, si se observa varios en rangos de 1 o cercanos a 1, definitivamente existe \"varianzas\" compartidas entre las variables; así que, en esas situaciones es cuando se aplicar PCA. Para machine learning, es una técnica bastante práctica, la razon es porque ayuda a que los modelos utilicen matrices de datos más pequeñas (con menos componentes), pero que al final de cuentas mantienen la misma relación entre ellos, por lo que explican los mismos datos y así influyen de la misma forma en la predicción.\n"
      ],
      "metadata": {
        "id": "YY_gUn2RkNF-"
      }
    }
  ]
}